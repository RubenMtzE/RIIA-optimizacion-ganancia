{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizacion_de_ganacias_riiaa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwHspCPXBXFn",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amunoz88/RIIA-optimizacion-ganancia/blob/master/notebooks/revenue_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhXipLIaCfP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import tensorboard\n",
        "import datetime\n",
        "import tensorflow\n",
        "from google.colab import files\n",
        "from tensorflow import keras\n",
        "import bisect\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bmrpHeOJqz5",
        "colab_type": "text"
      },
      "source": [
        "#Descripción del problema#\n",
        "Queremos determinar los mejores precios para objectos que queremos vender. Por ejemplo, cuando vendemos anuncios en internet, nos gustaría saber cuanto debemos cobrar por cada anuncio.\n",
        "\n",
        "En algunos casos, tenemos un historial de cuanto está dispuesto a pagar una persona por algún objeto. Por ejemplo en eBay tenemos transacciones históricas, en AirBnb vemos cuanto paga la gente por departamentos, ...\n",
        "\n",
        "##Formalización\n",
        "Consideremos un conjunto de valores históricos $b_1, \\ldots, b_m$. Esto es lo que historicamente usuarios han estado dispuestos a pagar. Por ejemplo, cuánto se ha rentado una casa en Airbnb, cuánto se ha pagado por objectos en eBay... Nuestra meta es seleccionar un precio $p$ que maximice nuestras ganancias históricas. Notemos que si $b_i < p$, no obtenemos ninguna ganancia. Si $b_i > p$ entonces nuestra ganancia es $p$. Por lo tanto queremos maximizar:\n",
        "\n",
        "$$ G(p) = \\sum_{i=1}^m p \\mathbf{1}\\{b_i \\geq p\\}$$\n",
        "\n",
        "### Variantes\n",
        "El problem anterior puede tener las siguientes variantes\n",
        " * Subastas de segundo precio: En una subasta de segundo precio multiplles agentes dicen cuanto están dispuestos a pagar. El ganador es quien está dispuesto a pagar más y termina pagando el máximo entre la segunda ooferta más alta y un precio mínimo $p$. Si denotamos por $b^{(1)}$ la oferta más alta y por $b^{(2)}$ la segunda oferta más alta el problema se reduce a maximizar $$G(p) = \\sum_{i=1}^m \\max(b^{(2)}_i , p) \\mathbf{1}\\{b^{(1)}_i \\geq p\\}$$. Este tipo de subastas es muy común cuando se venden objetos en internet como anuncios y objetos en eBay.\n",
        " * Inclusión de covariantes (features). Podemos codificar la información sobre el objeto en venta y el comprador en un vector $x$. Nuestro precio puede ser una función de $x$. Por ejemplo, en airbnb el precio de un departamento depende del número de cuartos, de la temporada en que se visita la ciudad, ...Nuestros datos ahora corresponden a pares $(x_i, b_i)$, donde $b_i$ es el precio que alguien está dispuesto a pagar por el objeto descrito por $x_i$.  Nuestra meta es resolver $$\\max_{p \\in \\mathcal{P}} G(p) = \\sum_{i=1}^m p(x_i) \\mathbf{1} \\{ b_i \\geq p(x_i)\\},$$ donde la familia $\\mathcal{P}$ contiene funciones que mapea atributos (features) a valores reales. Por ejemplo $\\mathcal{P}$ puede ser un conjunto de funciones lineales o redes neuronales.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsG5j29sRDhw",
        "colab_type": "text"
      },
      "source": [
        "#Ejercicio 1\n",
        "##Implementación de las funciones de ganancia. \n",
        "Implementa la función _ganancia con parametro p y que toma como argumento un np.array de ofertas. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwrO4fsARCI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Implementación de la función de ganancia\n",
        "def _ganancia(p, b):\n",
        "  \"\"\" Función de ganancia.\n",
        "  Args:\n",
        "    p: Un scalar\n",
        "    b: Un np.array de ofertas b_1, ... b_m\n",
        "  Returns:\n",
        "    La ganancia histórica si ponemos un precio p. \n",
        "  \"\"\"\n",
        "\n",
        "def ganancia(p, b):\n",
        "  \"\"\" Función de ganancia con argumento de vector\n",
        "  Args:\n",
        "    p: Un np.array\n",
        "    b: Un np.array de overtas b_1, ..., b_m\n",
        "  Returns:\n",
        "    Un np.array de ganancias por cada entrada en p.\n",
        "  \"\"\"\n",
        "  return np.array([_ganancia(pp,b) for pp in p])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9sl4_uaQ5wx",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot de la función de ganancia para una sola oferta\n",
        "b =  2.0#@param\n",
        "bb = np.array(b)\n",
        "p = np.linspace(0, 8, 100)\n",
        "plt.plot(p, ganancia(p, bb))\n",
        "plt.xlabel(\"p\")\n",
        "l=plt.ylabel(\"Ganancia\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvl-PSFWSucM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot de la función de ganancia con 20 ofertas ~ U(0,1)\n",
        "b = np.random.uniform(0, 1, 20)\n",
        "p = np.linspace(0, 1, 100)\n",
        "plt.plot(p, ganancia(p, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPMz3uztT4tc",
        "colab_type": "text"
      },
      "source": [
        "#Ejercicio 2\n",
        "## Optimizar mis ganancias\n",
        "Dado un conjunto de ofertas como obtener el precio que maximize mis ganancias?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnrJSQhmT32Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Implementa una función que optimize la ganancia histórica\n",
        "def optimizar_ganancias(b):\n",
        "  \"\"\" Función para optimizar la ganacia histórica dadoo un vector de ofertas\n",
        "     Args:\n",
        "       b: Un vector de ofertas\n",
        "     Returns:\n",
        "       max: la máxima ganancia posible\n",
        "       a_max: el precio que optimiza la ganancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPB0poSmTknj",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9d6875c8-7ed2-4d57-976e-bd4336519ee4"
      },
      "source": [
        "#@title Cargar ofertas. Suban el archivo bids.txt del repositorio\n",
        "def LoadBids():\n",
        "  uploaded = files.upload()\n",
        "  str_array = uploaded['bids.txt'].decode().split(\",\")\n",
        "  return np.array([float(b) for b in str_array])\n",
        "ofertas = LoadBids()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c0319123-6462-48e3-8cfe-bdcf6731e1ff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c0319123-6462-48e3-8cfe-bdcf6731e1ff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving bids.txt to bids.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oBvpCl7Vsqx",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Código de evaluación.\n",
        "p = np.linspace(0, 15, 100)\n",
        "plt.plot(p, ganancia(p, ofertas))\n",
        "plt.ylabel(\"ganancia\")\n",
        "plt.xlabel(\"p\")\n",
        "init_time = time.time()*1000\n",
        "m, am = optimizar_ganancias(ofertas)\n",
        "running_time = time.time() * 1000 - init_time\n",
        "plt.vlines(am, 0, m, color='red')\n",
        "plt.hlines(m, 0, p[99], color='red')\n",
        "print(\"Ganancia propuesta: %.4f. Solución en %.2f milisegundos\" % (ganancia([am], ofertas), running_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPoI3C0ui4GF",
        "colab_type": "text"
      },
      "source": [
        "#Ejercicio 3\n",
        "Introducción de atributos. Información sobre cada objecto es codificada en un vector $x \\in \\mathbb{R}^d$. Queremos predecir cuánto está dispuesto una persona a pagar por ese objecto. \n",
        "\n",
        "Solución tradicional es regresión: Dados ejemplos $(x_1, b_1), \\ldots, (x_n, b_n)$ encontrar un vector $w$ que minimize:\n",
        "\n",
        "$$ \\sum_{i=1}^n (p(x_i)  - b_i)^2$$.\n",
        "\n",
        "¿Pódemos usar las predicciones $p(x_i)$ como precios?\n",
        "\n",
        "\n",
        "Sube los archivos titulados ej3* del repositorio.  El siguient bloque crea los objetos:\n",
        "* X: Una matriz que contiene un vector de atributos por cada renglón\n",
        "* b: Un vector que contiene una oferta asociada a cada atributo\n",
        "* Xtest: Una matriz de datos usada para evaluar un modelo\n",
        "* btest: Vector de overtas usado para evaluar un modelo. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjuxxoXMo7g6",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "uploaded = files.upload()\n",
        "X = np.load(\"ej3_features.npy\").T\n",
        "b = np.load(\"ej3_costs.npy\")\n",
        "Xtest= np.load(\"ej3_features_test.npy\").T\n",
        "btest = np.load(\"ej3_costs_test.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GGT1a7fk_Ev",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Analiza el código que crea la structura de una red neuronal \n",
        "d = X.shape[1]\n",
        "def vector_revenue(p, b):\n",
        "  prices = np.maximum(p,0).reshape(-1)\n",
        "  buy = p.reshape(-1) <=b.reshape(-1)\n",
        "  return np.sum(prices * buy)\n",
        "\n",
        "def model_revenue(model, X, b):\n",
        "  return vector_revenue(model.predict(X), b)\n",
        "\n",
        "def create_neural_network(regularizer=0.001):\n",
        "  input = keras.Input((d, ))\n",
        "  relu_layer = keras.layers.Dense(40, use_bias=True, activation=keras.activations.relu,\n",
        "                                    kernel_regularizer=keras.regularizers.l2(regularizer))\n",
        "  linear_layer = keras.layers.Dense(1, use_bias=True, kernel_regularizer = keras.regularizers.l2(regularizer))\n",
        "  output = linear_layer(relu_layer(input))\n",
        "  model = keras.Model(inputs = input,outputs=output)\n",
        "  return model\n",
        "# Implementa esta función de ganancia. La función es una versión suave de\n",
        "# función de ganancia que implementaste in el ejercicio 1    \n",
        "# def tf_ganancia_smooth(ytrue, ypred, gamma):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBoXU0c2qkF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Entrena tu model con error cuadrático.\n",
        "batch_size = 1000  #@param\n",
        "epochs = 100 #@param\n",
        "funcion_perdida = \"cuadratica\" #@param \n",
        "\n",
        "gamma = 2.0\n",
        "square_loss = keras.losses.MeanSquaredError()\n",
        "rev_loss = lambda ytrue, ypred: -tf_ganancia_smooth(ytrue, ypred, gamma)\n",
        "model_loss = square_loss\n",
        "if funcion_perdida == \"ganancia\": \n",
        "  model_loss = rev_loss\n",
        "\n",
        "def train_model(batch_size, epochs, model_loss, regularizer = 0.001,verbose=False):\n",
        "  model = create_neural_network(regularizer)\n",
        "  model.compile(optimizer=keras.optimizers.Adam(0.1),\n",
        "              loss= model_loss)\n",
        "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "  model.fit(X, y=b,batch_size=batch_size, epochs=epochs,\n",
        "            callbacks=tensorboard_callback,validation_split=0.1,shuffle=True,\n",
        "            verbose=verbose)\n",
        "  return model\n",
        "  \n",
        "model = train_model(batch_size, epochs, model_loss, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRsPoeXvsoTG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Evalua tu modelo en datos de entrenamiento y de evaluacion\n",
        "print(\"Ganancia en datos de entrenamiento %.3f. En datos de evaluacion %.3f\" \n",
        "      % (model_revenue(model, X, b), model_revenue(model,Xtest, btest)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08r442FFa1t",
        "colab_type": "text"
      },
      "source": [
        "* ¿Cómo sabes si tu model es bueno o malo?\n",
        "* ¿Cuál es una cota inferior para la ganancia? ¿Superior?\n",
        "* Implementa tus cotas y averigua que tan bueno o malo es éste modelo.\n",
        "* ¿Cómo lo podemos mejorar?\n",
        "* Trata de implementar tf_ganancia_smooth y entrena tu modelo con funcion_perdida = \"ganancia\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gz1bF-XrUw4",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Opcional: visualiza el progreso de tu modelo en Tensorboard.\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ra0WzqIGenT",
        "colab_type": "text"
      },
      "source": [
        "### ¿Qué podemos hacer con predicciones que usan la pérdida cuadrática?\n",
        "[1] Andrés Muñoz Medina, Sergei Vassilvitskii. Revenue optimization with approximate bid predictions. \n",
        "La solución es usar clusters. Clusters con menos varianza nos ayudan a obtener más ganancias.\n",
        "#### Algoritmo:\n",
        "* Entrenamos un model usando pérdida cuadrática\n",
        "* Ponemos en k clusters las predicciones\n",
        "* Para cada cluster encontramos el precio óptimo usando la funcion optimizar_ganancias. \n",
        "\n",
        "#### Predicción\n",
        "* Predecimos la oferta usando el model\n",
        "* Encontramos el cluster al que la predicción pertenece\n",
        "* Usamos el precio óptimo calculado para ese cluster\n",
        "\n",
        "El código para este algoritmo no es trivial así que lo implementamos abajo. Las funciones principales son:\n",
        "* train_reserve_price_cluster_model\n",
        "* evaluate_cluster_model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOhvrccQl321",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Código de clusters\n",
        "\n",
        "def train_reserve_price_cluster_model(X, b, model,k):\n",
        "  \"\"\" Entrena un modelo de clusters usando un modelo de keras.\n",
        "  Args:\n",
        "    X: Matriz de \"features\"\n",
        "    b: Ofertas\n",
        "    model: Model de keras que predice ofertas.\n",
        "    k: Número de clusters deseados\n",
        "  Returns:\n",
        "    cutoffs: Los delimitadores de los clusters\n",
        "    cluster_to_prices: Un diccionario que mapea un número de cluster\n",
        "        a un precio de reserva.\n",
        "  \"\"\"\n",
        "  clusters, cutoffs = cluster_data_with_model(X, model, k=k)\n",
        "  cluster_to_bids = {}\n",
        "  for i,c in enumerate(clusters):\n",
        "    if c not in cluster_to_bids.keys():\n",
        "      cluster_to_bids[c] = []\n",
        "    cluster_to_bids[c].append(b[i])\n",
        "  cluster_to_prices = {}\n",
        "  cluster_to_prices[0] = 0.0\n",
        "  n = len(cutoffs)\n",
        "  cluster_to_prices[n] = cutoffs[n-1]\n",
        "  for c,bids in cluster_to_bids.items():\n",
        "    rev, p = optimizar_ganancias(bids)\n",
        "    cluster_to_prices[c] = p\n",
        "  return cutoffs, cluster_to_prices\n",
        "\n",
        "\n",
        "def evaluate_cluster_model(X, b, model, cutoffs, cluster_to_prices):\n",
        "  \"\"\" Evalua un modelo de clusters.\n",
        "\n",
        "  Args:\n",
        "    X = Matriz de \"features\"\n",
        "    b = Ofertas\n",
        "    model: Modelo de keras\n",
        "    cutoffs: Los delimitadores para clusters generatods por\n",
        "       train_reserve_price_cluster_model\n",
        "    cluster_to_prices: Diccionario que mapea numero de un cluster\n",
        "       a un precio de reserva\n",
        "    Returns:\n",
        "      La ganancia que se obtiene con este modelo.\n",
        "  \"\"\"\n",
        "  prices = _get_prices(np.maximum(model.predict(X), 0).reshape(-1),\n",
        "                      cutoffs, cluster_to_prices)\n",
        "  return vector_revenue(prices, b)\n",
        "\n",
        "def histogram_mean(v, weights=None):\n",
        "  #print v\n",
        "  #print weights\n",
        "  if  weights.any() == None:\n",
        "    weights = np.ones(len(v), float)\n",
        "  total_weight = np.sum(weights)\n",
        "  return np.sum(weights*v) /total_weight\n",
        "\n",
        "def histogram_var(v, weights=None):\n",
        "  if weights.any() == None:\n",
        "    weights = np.ones(len(v), float)\n",
        "  total_weight = np.sum(weights)\n",
        "  mean = histogram_mean(v, weights)\n",
        "  s2 = histogram_mean(v**2, weights)\n",
        "  return s2 - mean**2\n",
        "\n",
        "\"\"\" Minimize the clustered weighted variance to some power. That is\n",
        "   \\sum_{j=1}^k n_k \\sigma_k^{2 * power}.\n",
        "   Args:\n",
        "     v = sorted list for which we want to minimize the weighted variance.\n",
        "     k = number of clusters\n",
        "     power = float that represents the value at which we want to raise the\n",
        "             variance\n",
        "     weights = Optional, it should have the same length as v. weights[i]\n",
        "               represents the weight that should be given to v[i].\n",
        "     Returns:\n",
        "     The optimal clustering, cutoff values and the weighted variance\n",
        "     of the cluster. The clustering is represented by the indices of the cutoffs.\n",
        "     A new element x belongs to cluster i if cutoff[i-1] < x <= cutoff[i].\n",
        "     Where cutoff[-1] = -Inf and cutoff[k] = Inf.\n",
        "     Complexity O(len(v)**2)\"\"\"\n",
        "def DP_weighted_var(v, k, power, weights=None):\n",
        "  if weights == None:\n",
        "    weights = np.ones(len(v))\n",
        "  n = len(v)\n",
        "  # Dynamic programming matrix\n",
        "  DPmat = np.ones((n, k)) * 2**32\n",
        "  # Matrix to recover the indices of the optimal clustering\n",
        "  DPindex_mat = np.zeros((n, k), np.int)\n",
        "  DPindex_mat[0, 0] = 0\n",
        "  DPmat[0, 0] = 0.0\n",
        "  for i in range(1, n):\n",
        "    for j in range(min(i + 1, k)):\n",
        "      if j == 0:\n",
        "        # If only one cluster then the\n",
        "        DPmat[i, j] = (histogram_var(v[0:i + 1], weights[0:i+1]) **power\n",
        "                       * np.sum(weights[0:i+1]))\n",
        "        DPindex_mat[i, 0] = 0\n",
        "      else:\n",
        "        opt_value = 2**32\n",
        "        opt_index = 0\n",
        "        mean = v[i]\n",
        "        s2 = v[i]**2\n",
        "        total_current_weight = weights[i]\n",
        "        for s in range(i):\n",
        "          reverse_index = i - s\n",
        "          value = 0 \n",
        "          if s == 0:\n",
        "             value = DPmat[i-1, j-1]\n",
        "          else :\n",
        "            mean = ((total_current_weight * mean\n",
        "                    + v[reverse_index] * weights[reverse_index])/\n",
        "                    (total_current_weight + weights[reverse_index]))\n",
        "            s2 = (s2 * total_current_weight  + v[reverse_index]**2 * weights[reverse_index])/(total_current_weight + weights[reverse_index])\n",
        "            total_current_weight += weights[reverse_index]\n",
        "            value = (s2 - mean**2) ** power * total_current_weight + DPmat[reverse_index - 1, j-1]\n",
        "          index = reverse_index\n",
        "          if value <= opt_value:\n",
        "            opt_value = value\n",
        "            opt_index = index\n",
        "        DPmat[i, j] = opt_value\n",
        "        DPindex_mat[i, j] = opt_index\n",
        "  # Recover the solution from the DP matrix.\n",
        "  indices = [0] * k\n",
        "  current_index = n - 1\n",
        "  for j in range(0, k)[::-1]:\n",
        "    indices[j] = DPindex_mat[current_index, j]\n",
        "    current_index = indices[j] - 1\n",
        "  return (indices, [v[s] for s in indices], DPmat[n - 1, k - 1])\n",
        "\n",
        "def _assign_to_cutoff(value, cutoffs):\n",
        "  if value < cutoffs[0]:\n",
        "    return 0\n",
        "  if value > cutoffs[len(cutoffs) -1]:\n",
        "    return len(cutoffs)\n",
        "  return bisect.bisect_right(cutoffs, value)\n",
        "def _assign_to_cutoffs(values, cutoffs):\n",
        "  return [_assign_to_cutoff(value, cutoffs) for value in values]\n",
        "\n",
        "def _train_cluster_model(predictions, k):\n",
        "  sorted_pred = quantize_predictions(predictions, 1000)\n",
        "  _, cutoffs, _ = DP_weighted_var(sorted_pred,k, 1.0/3.0)\n",
        "  return  _assign_to_cutoffs(predictions, cutoffs), cutoffs\n",
        "\n",
        "def quantize_predictions(predictions, num_quantiles):\n",
        "  if num_quantiles > len(predictions):\n",
        "    return np.sort(predictions)\n",
        "  return np.quantile(predictions,\n",
        "                    np.linspace(1.0/num_quantiles, 1.0, num_quantiles))\n",
        "  \n",
        "def cluster_data_with_model(X, model, cutoffs=None, k=None):\n",
        "  predictions = np.maximum(model.predict(X),0).reshape(-1)\n",
        "  if cutoffs != None:\n",
        "    return _assign_to_cutoffs(predictions, cutoffs), cutoffs\n",
        "  return _train_cluster_model(predictions, k)\n",
        "\n",
        "def _get_prices(predictions, cutoffs, cluster_to_prices):\n",
        "  clusters = _assign_to_cutoffs(predictions, cutoffs)\n",
        "  prices = np.zeros_like(predictions)\n",
        "  for i,c in enumerate(clusters):\n",
        "    prices[i] = cluster_to_prices[c]\n",
        "  return prices\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
